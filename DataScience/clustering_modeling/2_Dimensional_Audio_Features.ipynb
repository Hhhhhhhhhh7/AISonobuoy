{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f783dc9",
   "metadata": {},
   "source": [
    "# Creating 2-Dimesional Audio Feature Vectors for Clustering \n",
    "\n",
    "This notebook borrows heavliy from the following three sources: \n",
    "\n",
    "- [Audio Signal Processing for Machine Learning](https://www.youtube.com/playlist?list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0)\n",
    "- [librosa](https://librosa.org/doc/main/index.html)\n",
    "- [Audio Feature Extraction](https://devopedia.org/audio-feature-extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d969e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Latex\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        print(\"Process Terminated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f3150",
   "metadata": {},
   "source": [
    "### Env Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e6ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import librosa\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from tempfile import mktemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca57ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/home/ec2-user/tugboat_interval_ds\"\n",
    "TUGBOAT_PATH = os.path.join(ROOT, \"tugboat\")\n",
    "NOISE_PATH = os.path.join(ROOT, \"no_tugboat\")\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "FRAME_LENGTH = 2048\n",
    "HOP_LENGTH = FRAME_LENGTH // 2\n",
    "WINDOW_LENGTH = FRAME_LENGTH\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "FRAME_LENGTH = 1024\n",
    "HOP_LENGTH = 256\n",
    "INTERVAL_LENGTH = 1\n",
    "\n",
    "RESNET_INPUT_SHAPE = (3, 224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e10e68",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c811612",
   "metadata": {},
   "outputs": [],
   "source": [
    "tugboat_files_ls = [\n",
    "    os.path.join(TUGBOAT_PATH, x)\n",
    "    for x in os.listdir(TUGBOAT_PATH)\n",
    "    if x.endswith(\".wav\")\n",
    "]\n",
    "noise_files_ls = [\n",
    "    os.path.join(NOISE_PATH, x) for x in os.listdir(NOISE_PATH) if x.endswith(\".wav\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af72794e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4030, 2918)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tugboat_files_ls), len(noise_files_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db580a84",
   "metadata": {},
   "source": [
    "### Window Features Driver Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b8287b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save(\n",
    "    file_ls,\n",
    "    out_dir,\n",
    "    feature_func,\n",
    "    feature_interval=INTERVAL_LENGTH,\n",
    "    sampling_rate=SAMPLING_RATE,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    frame_length=FRAME_LENGTH,\n",
    "):\n",
    "    target_ctr = 0\n",
    "    for file in file_ls:\n",
    "        prev_idx = 0\n",
    "        signal, sampling_rate = librosa.load(file, sr=sampling_rate)\n",
    "\n",
    "        for curr_idx in range(\n",
    "            sampling_rate * feature_interval,\n",
    "            len(signal),\n",
    "            sampling_rate * feature_interval,\n",
    "        ):\n",
    "            window = signal[prev_idx:curr_idx]\n",
    "            if len(window) > 0:\n",
    "                save_feature = feature_func(\n",
    "                    window,\n",
    "                    interval_length=INTERVAL_LENGTH,\n",
    "                    sr=SAMPLING_RATE,\n",
    "                    frame_length=FRAME_LENGTH,\n",
    "                    hop_length=HOP_LENGTH,\n",
    "                    y_axis=\"log\",\n",
    "                )\n",
    "                np.save(os.path.join(out_dir, str(target_ctr)), save_feature)\n",
    "                target_ctr += 1\n",
    "                prev_idx += sampling_rate * feature_interval\n",
    "\n",
    "    return f\"Saved {target_ctr} features\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0c3c62",
   "metadata": {},
   "source": [
    "### Spectrogram\n",
    "\n",
    "larroes catch medloes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20cf2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "SG_TUG_OUT = \"/home/ec2-user/clustering/spectrogram/tugboat\"\n",
    "SG_NOISE_OUT = \"/home/ec2-user/clustering/spectrogram/no_tugboat\"\n",
    "\n",
    "os.makedirs(SG_TUG_OUT, exist_ok=True)\n",
    "os.makedirs(SG_NOISE_OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31146037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_and_drop_alpha(filepath):\n",
    "    tensor = torchvision.io.read_image(filepath)\n",
    "    if tensor.shape[1] < RESNET_INPUT_SHAPE[1]:\n",
    "        tensor = torch.nn.functional.pad(\n",
    "            tensor, (0, 0, RESNET_INPUT_SHAPE[1] - tensor.shape[1], 0), \"constant\", 0\n",
    "        )\n",
    "    if tensor.shape[2] < RESNET_INPUT_SHAPE[2]:\n",
    "        tensor = torch.nn.functional.pad(\n",
    "            tensor, (RESNET_INPUT_SHAPE[2] - tensor.shape[2], 0), \"constant\", 0\n",
    "        )\n",
    "    if tensor.shape[0] > RESNET_INPUT_SHAPE[0]:\n",
    "        tensor = tensor[:3, :, :]\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def create_spectrogram(signal, sr, frame_size, hop_length, y_axis=\"linear\"):\n",
    "    fft = librosa.stft(signal, n_fft=frame_size, hop_length=hop_length)\n",
    "    y = np.abs(fft) ** 2\n",
    "    y = librosa.power_to_db(y)\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.dpi = 45\n",
    "\n",
    "    librosa.display.specshow(\n",
    "        y, sr=sr, hop_length=hop_length, x_axis=\"time\", y_axis=y_axis\n",
    "    )\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.axis(\"off\")\n",
    "    plt.set_cmap(\"turbo\")\n",
    "    fname = mktemp(\".png\")\n",
    "\n",
    "    plt.savefig(fname, dpi=45, bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close()\n",
    "    return fname\n",
    "\n",
    "\n",
    "def create_spectrogram_driver(\n",
    "    signal,\n",
    "    interval_length=INTERVAL_LENGTH,\n",
    "    sr=SAMPLING_RATE,\n",
    "    frame_length=FRAME_LENGTH,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    y_axis=\"log\",\n",
    "):\n",
    "    fname = create_spectrogram(signal, sr, frame_length, hop_length, y_axis=y_axis)\n",
    "    tensor = pad_and_drop_alpha(filepath=fname)\n",
    "    return tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdba1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_save(\n",
    "    tugboat_files_ls,\n",
    "    SG_TUG_OUT,\n",
    "    create_spectrogram_driver,\n",
    "    feature_interval=INTERVAL_LENGTH,\n",
    "    sampling_rate=SAMPLING_RATE,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    frame_length=FRAME_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a83dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_save(\n",
    "    noise_files_ls,\n",
    "    SG_NOISE_OUT,\n",
    "    create_spectrogram_driver,\n",
    "    feature_interval=INTERVAL_LENGTH,\n",
    "    sampling_rate=SAMPLING_RATE,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    frame_length=FRAME_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca2f5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
